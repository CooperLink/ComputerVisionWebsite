<!DOCTYPE html>
<html lang="en"><head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta charset="utf-8">
  <title>Computer Vision Class Project
  | CS, Georgia Tech | Fall 2020: CS 4641</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="">
  <meta name="author" content="">

<!-- Le styles -->
  <link href="css/bootstrap.css" rel="stylesheet">
<style>
body {
padding-top: 60px; /* 60px to make the container go all the way to the bottom of the topbar */
}
.vis {
color: #3366CC;
}
.data {
color: #FF9900;
}
</style>

<link href="css/bootstrap-responsive.min.css" rel="stylesheet">

<!-- HTML5 shim, for IE6-8 support of HTML5 elements --><!--[if lt IE 9]>
<script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->
</head>

<body>
<div class="container">
<div class="page-header">

<!-- Title and Name -->
<h1>Your Title Here</h1>
<span style="font-size: 20px; line-height: 1.5em;"><strong>Devarsi Rawal, Cooper Link, Kevin Li, Matt Carroll, Saloni Shah</strong></span><br>
<span style="font-size: 18px; line-height: 1.5em;">Fall 2020 CS 4641 Computer Vision: Class Project</span><br>
<span style="font-size: 18px; line-height: 1.5em;">Georgia Tech</span>
<hr>

<!-- Goal -->
<h3>Problem Statement</h3>

<p>Given an input portrait and an input face, create an artistically styled interpretation of the photo that has the picture of the
input face mapped onto the input portrait. If no face is detected in the input portrait, the input face is mapped into the input
portrait using texture mapping. If a face is included in the input portrait, the input face replaces the detected face using
landmark matching and also preserves the original portrait’s artistic style and geometric proportions. For instance, if a
user inputs their face and Van Gogh’s Starry Night, the expected output image would have the user’s face ingrained in the
overall portrait’s background, as there are no faces in Starry Night. However, if a user inputs da Vinci’s Mona Lisa instead
of Starry Night, Lisa’s face would be replaced with an altered version of the user’s face that matches the artist’s style and facial dimensions.
</p>
<br><br>
<!-- figure -->
<h3>Teaser figure</h3>
<p>
A figure that conveys the main idea behind the project or the main application being addressed.
</p>
<br><br>
<!-- Main Illustrative Figure -->
<div style="text-align: center;">
<img style="height: 200px;" alt="" src="mainfig.png">
</div>

<br><br>
<!-- Approach -->
<h3>Approach</h3>
<p>
    The first step is to use Viola-Jones algorithm to detect any faces in the painting. We will implement this algorithm ourselves.
    If there are faces detected in the artwork we will use OpenCV to detect facial landmarks on all the detected faces. We will detect the facial landmarks
    based off of the shape predictor <a href="https://github.com/codeniko/shape_predictor_81_face_landmarks">here</a>. This landmark detection algorithm
    finds 81 facial feature landmarks including the forehead. An example of this is below:
    <img style="height: 300px; display: block; margin: 20px auto 20px auto;" alt="" src="facial-features.jpg">
    To preserve the geometric style of the painting, we will warp the human source image to match the geometric characteristics of the painting source image.
    This will be done by using the landmark points to perform a non-parametric face warp using triangular affine matrices. This will be done using code found
    <a href="https://github.com/alyssaq/face_morpher/blob/dlib/facemorpher/warper.py">here</a>. This contains code taht can be used to warp faces based on anchor points,
    so it is particularly applicable to our method.
</p>
<p>
    The next step is the blending of the face and artwork. We will map the face from the photo onto the painting. This will be accomplished by two different approaches
    we will implement. The first being a Poission blending which will adapt from <a href="https://github.com/willemmanuel/poisson-image-editing/blob/master/poisson.py">here</a>.
    The second approach will be weight masks based on facial feature segmentation. This will be done by creating a polygon based on the landmark features found previously, 
    which have numbers assigned to regions, and simply map those regions onto the painting using different weights for different features based on what we find to be the most critical points.
</p>
<p>
    In addition to the above, if there is no face detected by the Viola-Jones algorithm then we will be apply the painting's texture onto the image of the face. 
</p>

<br><br>
<!-- Results -->
<h3>Experiments and results</h3>
<p>
Provide details about the experimental set up (number of images/videos, number of datasets you experimented with, train/test split if you used machine learning algorithms, etc.). Describe the evaluation metrics you used to evaluate how well your approach is working. Include clear figures and tables, as well as illustrative qualitative examples if appropriate. Be sure to include obvious baselines to see if your approach is doing better than a naive approach (e.g. for classification accuracy, how well would a classifier do that made random decisions?). Also discuss any parameters of your algorithms, and tell us how you set the values of those parameters. You can also show us how the performance varies as you change those parameter values. Be sure to discuss any trends you see in your results, and explain why these trends make sense. Are the results as expected? Why?
</p>
<br><br>

<!-- Main Results Figure -->
<div style="text-align: center;">
<img style="height: 300px;" alt="" src="results.png">
</div>
<br><br>


  <hr>
  <footer>
  <p>© Devarsi Rawal, Cooper Link, Kevin Li, Matt Carroll, Saloni Shah</p>
  </footer>
</div>
</div>

<br><br>

</body></html>