<!DOCTYPE html>
<html lang="en"><head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta charset="utf-8">
  <title>Computer Vision Class Project
  | CS, Georgia Tech | Fall 2020: CS 4476</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="">
  <meta name="author" content="">

<!-- Le styles -->
  <link href="css/bootstrap.css" rel="stylesheet">
<style>
body {
padding-top: 60px; /* 60px to make the container go all the way to the bottom of the topbar */
}
.vis {
color: #3366CC;
}
.data {
color: #FF9900;
}
</style>

<link href="css/bootstrap-responsive.min.css" rel="stylesheet">

<!-- HTML5 shim, for IE6-8 support of HTML5 elements --><!--[if lt IE 9]>
<script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->
</head>

<body>
<div class="container">
<div class="page-header">

<!-- Title and Name -->
<h1>Artistic Stylization of Faces</h1>
<span style="font-size: 20px; line-height: 1.5em;"><strong>Cooper Link, Devarsi Rawal, Kevin Li, Matt Carroll, Saloni Shah</strong></span><br>
<span style="font-size: 18px; line-height: 1.5em;">Fall 2020 CS 4476 Computer Vision: Class Project</span><br>
<span style="font-size: 18px; line-height: 1.5em;">Georgia Tech</span>
<hr>

<!-- Abstract -->
<h3>Abstract</h3>

  <p>
    The goal of our project is to create an artistically styled interpretation of a portrait that maps important features of an input face onto an input painting without sacrificing the geometric proportions and color palate of the painting. For this update, we decided to split our project into pieces that would then be combined into a pipeline for our final update. We implemented the Viola-Jones algorithm, facial landmark detection, image quilting for texture transfer, and mixed cloning using poisson blending this stage independently. We found that each individual portion of our greater project performed the required function that it needed to perform, and our qualitative results show the test cases that we fed into the algorithms. 
  </p>
</p>
<br><br>
<!-- figure -->
<h3>Teaser figure</h3>
<p>
  <div style="text-align: center;">
    <img style="height: 200px;" alt="" src="zvi.jpg">
    <img style="height: 200px;" alt="" src="mixedSeamClone.PNG">
    <img style="height: 200px;" alt="" src="wheatzvi.jpg">
    <img style="height: 200px;" alt="" src="lisa.png">
  </div>
</p>
<br><br>
<!-- Approach -->
<h3>Approach</h3>
<p>
  In order to achieve our goal of artistically mapping a painter’s style onto an input human face, we must utilize various techniques. First, to determine if a painting contains a face, we will use the Viola-Jones algorithm [1]. If a face does not exist, we will simply use a texture generation algorithm [2] to map the landscape painting’s style onto the input face. If a face does exist (and we will have to take into account the possibility of multiple faces), we will have to detect facial landmarks. There exists a previous implementation [3] of this in Python using dlib and OpenCV that we will be able to exploit. Our ultimate goal is to produce results that appear similar to those seen in The Face of Art project [4]. To achieve this, we want to preserve the geometric style of the painting by warping the human source image to match the geometric characteristics of the portrait painting in relation to the face landmark points. We have two ideas for our warping algorithm:
</p>
  <ol>
    <li> Non-parametric warping using triangular affine matrices [5] </li>
    <li> Moving Least Squares algorithm [6] to average the image </li>
  </ol>
<p>
  To map the artistic styles from image to image, we can go two ways: map the human face onto the painting, or vice versa. Either way, we can implement one of two approaches: Poisson blending [7] or weight masks based on facial feature segmentation. For weight masks, we can simply create a polygon based on the landmark features found previously (the points have ranges assigned to each region) and map those regions over using different weights for different features. The output will then result in an artistically styled face that preserves the original geometry of the painting. 
</p>

<br><br>
<!-- Results -->
<h3>Experiments and Results</h3>
<h4>Viola-Jones Face Recognition</h4>
<p>Viola</p>
<h4>Image Quilting for Texture Transfer</h4>
<p>
  Our experimental set up for the texture transfer was simple. We used a variety of portraits that did not contain faces as our base and an image of Zvi as our person’s headshot photo. We evaluated this portion of the project qualitatively as the objective of texture transfer using image quilting is to transfer textures as smoothly to the human eye as possible. Because there is no learning involved, qualitative analysis would be the most appropriate way of examination. 
  <div style="text-align: center;">
    <img style="height: 200px;" alt="" src="zvi.jpg">
    <img style="height: 200px;" alt="" src="wheatfield.jpeg">
    <img style="height: 200px;" alt="" src="wheatzvi.jpg">
  </div>
</p>
<p>
  Here are two examples of Zvi being integrated using the texture of Van Gogh’s Starry Night and Van Gogh’s Wheatfield with Cypresses.  A naive approach to texture mapping would be to reduce the transparency of the person’s face and place it in front of the portrait. This would essentially overlay the image of the person’s face on top of the portrait. This is the incorrect way to do this, and examples of this image overlay are shown below.
  <div style="text-align: center;">
    <img style="height: 200px;" alt="" src="naivenight.jpg">
    <img style="height: 200px;" alt="" src="naivewheat.jpg">
  </div>
</p>
<p>
  The parameters for our algorithm that can be changed are the alpha value which determine how much the person’s face’s shape and edges are factored into the final texture map. The alpha value we used was 0.8, which was suggested by the Efros paper. Another parameter that was used was the amount of overlap that two texture blocks would have before stitching them together. We utilized 1/6 of the texture block size as this was also suggested by the paper. 
</p>
<p>
  A trend that we saw was that, when it comes to portraits, because they do not have a relatively uniform texture, the texture that is used to recreate the person’s face is often the same. This result was expected because the variation among a person’s face is often minute, meaning that similar corresponding textures from the portrait would be chosen as the transfer texture for each “block” of the face. This is a benefit, as the person’s face can be more easily ingrained into the background of the photo, because the face is less varied.
</p>
<h4>Facial Landmark Detection</h4>
<p>Facial</p>
<h4>Seamless Cloning Using Poisson Blending</h4>
<p>Poisson</p>
<br><br>

<!-- Qualitative Results-->
<h3>Qualitative Results</h3>
<h4>Viola-Jones Face Recognition</h4>
<p>Viola</p>
<h4>Image Quilting for Texture Transfer</h4>
<p>
  <div style="text-align: center;">
    <img style="height: 200px;" alt="" src="wheatfield.jpeg">
    <img style="height: 200px;" alt="" src="wheatzvi.jpg">
  </div>
</p>
<p>
  <div style="text-align: center;">
    <img style="height: 200px;" alt="" src="night.jpg">
    <img style="height: 200px;" alt="" src="zvinight.jpg">
  </div>
</p>
<h4>Facial Landmark Detection</h4>
<p>Facial</p>
<h4>Seamless Cloning Using Poisson Blending</h4>
<p>Poisson</p>

<!-- Conclusion -->
<h3>Conclusion and Future Work</h3>
<p>
  A future goal would be to increase the speed at which the texture transfer takes. The time it took for the entire algorithm to run to completion was around an hour with both images being under 500x500 pixels. The amount of time it takes for it to run might turn off users, so we will need to look into ways to speed up our algorithm or pivot to neural networks that can run at much faster speeds [2].
</p>

<!-- References -->
<h3>References</h3>
<p>[1] https://en.wikipedia.org/wiki/Viola%E2%80%93Jones_object_detection_framework</p>
<p>[2] http://www.cs.harvard.edu/~sjg/apr/</p>
<p>[3] https://github.com/codeniko/shape_predictor_81_face_landmarks</p>
<p>[4] https://github.com/papulke/face-of-art</p>
<p>[5] https://www.csie.ntu.edu.tw/~cyy/courses/vfx/18spring/lectures/handouts/lec05_morphing.pdf</p>
<p>[6] https://people.engr.tamu.edu/schaefer/research/mls.pdf</p>
<p>[7] http://cs.brown.edu/courses/cs195-g/asgn/proj2/resources/PoissonImageEditing.pdf</p>
<p>[8] https://faculty.idc.ac.il/arik/site/foa/artistic-faces-dataset.asp</p>
<p>[9] https://ibug.doc.ic.ac.uk/resources/facial-point-annotations/</p>
<p>[10] https://www.kaggle.com/ikarus777/best-artworks-of-all-time</p>
<p>[11] https://github.com/alyssaq/face_morpher/blob/dlib/facemorpher/warper.py</p>
<p>[12] https://github.com/Jarvis73/Moving-Least-Squares</p>
<p>[13] https://github.com/willemmanuel/poisson-image-editing/blob/master/poisson.py</p>
<br><br>


<br><br>


  <hr>
  <footer>
  <p>© Devarsi Rawal, Cooper Link, Kevin Li, Matt Carroll, Saloni Shah</p>
  </footer>
</div>
</div>

<br><br>

</body></html>
