<!DOCTYPE html>
<html lang="en"><head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta charset="utf-8">
  <title>Computer Vision Class Project
  | CS, Georgia Tech | Fall 2020: CS 4641</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="">
  <meta name="author" content="">

<!-- Le styles -->
  <link href="css/bootstrap.css" rel="stylesheet">
<style>
body {
padding-top: 60px; /* 60px to make the container go all the way to the bottom of the topbar */
}
.vis {
color: #3366CC;
}
.data {
color: #FF9900;
}
</style>

<link href="css/bootstrap-responsive.min.css" rel="stylesheet">

<!-- HTML5 shim, for IE6-8 support of HTML5 elements --><!--[if lt IE 9]>
<script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->
</head>

<body>
<div class="container">
<div class="page-header">

<!-- Title and Name -->
<h1>Your Title Here</h1>
<span style="font-size: 20px; line-height: 1.5em;"><strong>Devarsi Rawal, Cooper Link, Kevin Li, Matt Carroll, Saloni Shah</strong></span><br>
<span style="font-size: 18px; line-height: 1.5em;">Fall 2020 CS 4641 Computer Vision: Class Project</span><br>
<span style="font-size: 18px; line-height: 1.5em;">Georgia Tech</span>
<hr>

<!-- Goal -->
<h3>Problem Statement</h3>

  <p>
    The goal of our project is to create an artistically styled interpretation of a portrait that maps important features of an input face onto an input 
    painting without sacrificing the geometric proportions and color palatte of the painting . If no face is detected in the input painting, the input face 
    will be ingrained into the input portrait’s background using texture mapping. If a face is included in the input painting, the input face will replace the
    detected portrait face using landmark matching while preserving the original portrait’s artistic style and geometric proportions. <br>
    For instance, if a user inputs their face and Van Gogh’s Starry Night, the expected output image would have the user’s face ingrained in the overall 
    painting’s background, as there are no faces in Starry Night. However, if a user inputs Da Vinci’s Mona Lisa instead of Starry Night, Lisa’s face would
    be replaced with an altered version of the user’s face that matches the artist’s style and facial dimensions.
  </p>
</p>
<br><br>
<!-- figure -->
<h3>Teaser figure</h3>
<p>
A figure that conveys the main idea behind the project or the main application being addressed.
</p>
<br><br>
<!-- Main Illustrative Figure -->
<div style="text-align: center;">
<img style="height: 200px;" alt="" src="mainfig.png">
</div>

<br><br>
<!-- Approach -->
<h3>Approach</h3>
<p>
    The first step is to use the Viola-Jones algorithm to detect any faces in the painting. We will implement this algorithm ourselves.
    If there are faces detected in the artwork we will use OpenCV to detect facial landmarks on all the detected faces. We will detect the facial landmarks
    based off of the shape predictor <a href="https://github.com/codeniko/shape_predictor_81_face_landmarks">here</a>. This landmark detection algorithm
    finds 81 facial feature landmarks including the forehead. An example of this is below:
    <img style="height: 300px; display: block; margin: 20px auto 20px auto;" alt="" src="facial-features.jpg">
    To preserve the geometric style of the painting, we will warp the human source image to match the geometric characteristics of the painting source image.
    This will be done by using the landmark points to perform a non-parametric face warp using triangular affine matrices. This will be done using code found
    <a href="https://github.com/alyssaq/face_morpher/blob/dlib/facemorpher/warper.py">here</a>. This contains code that can be used to warp faces based on anchor points,
    so it is particularly applicable to our method.
</p>
<p>
    The next step is the blending of the face and artwork. We will map the face from the photo onto the painting. This will be accomplished by two different approaches
    we will implement. The first being a Poisson blending which will adapt from <a href="https://github.com/willemmanuel/poisson-image-editing/blob/master/poisson.py">here</a>.
    The second approach will be weight masks based on facial feature segmentation. This will be done by creating a polygon based on the landmark features found previously, 
    which have numbers assigned to regions, and simply map those regions onto the painting using different weights for different features based on what we find to be the most critical points.
</p>
<p>
    In addition to the above, if there is no face detected by the Viola-Jones algorithm then we will be applying the painting's texture onto the image of the face. 
</p>

<br><br>
<!-- Results -->
<h3>Experiments and results</h3>
<p>
    With regards to our experimental setup, as previously stated, we want to limit our dependence on neural networks such that we do not need to perform any sort of learning on our own.
    We can stay within this constraint by using a pre-trained model for 81-point facial landmark detection. Besides this model, we do not intend on using any neural network or learning technique.
    The datasets we will use to test our methodology are mainly inspired by The Face of Art project; we will utilize the Artistic-Faces dataset offered by IDC Herzliya and the IBUG 300 Faces in
    the Wild dataset implicitly via the face landmark model. We will also utilize the Best Artworks of All Time dataset in order to test our texture mapping algorithm on landscape paintings.
    Our implementation will draw inspiration from many sources and exploit some previous code. We will use the aforementioned 81-point face landmark model, a face warping algorithm implemented
    using dlib, an MLS algorithm, and a Poisson Image editing algorithm. With that given, we will have to implement our own form of Viola-Jones to detect faces in portraits, a texture mapping
    algorithm for landscape paintings, a style-transfer algorithm using facial feature weight masks, and some small changes to the pre-existing code in order to make it cooperate with our code.
    The experiments we will perform are as follows: a) test with landscape paintings, b) test with portrait paintings, c) test with portrait/landscape paintings with two or more faces, d) measure
    effectiveness of mapping artistic style of painting onto input human image, e) measure effectiveness of blending input human image into the painting itself, f) measure effectiveness using
    varying parameter values and weights. We will verify the outcomes of these experiments by qualitatively comparing them to the outputs generated by The Face of Art style transfer implementation.
</p>
<br><br>

<!-- Main Results Figure -->
<div style="text-align: center;">
<img style="height: 300px;" alt="" src="results.png">
</div>
<br><br>


  <hr>
  <footer>
  <p>© Devarsi Rawal, Cooper Link, Kevin Li, Matt Carroll, Saloni Shah</p>
  </footer>
</div>
</div>

<br><br>

</body></html>
